---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: Cette section couvre les étapes de déploiement de NetApp XCP pour le transfert de données. 
---
= Étapes de déploiement
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Cette section couvre les étapes de déploiement de NetApp XCP pour le transfert de données.



== Détails du banc d'essai

Le tableau suivant fournit les détails du banc d’essai utilisé pour ce déploiement et la validation des performances.

|===
| Composants de la solution | Détails 


| XCP version 1.7  a| 
* Un serveur Linux - Linux (RHEL 7.9 ou RHEL 8)
* Un serveur Windows – Windows Server 2019 standard




| Paire de baies de stockage NetApp AFF HA pour le volume source  a| 
* AFF8080
* NetApp ONTAP 9
* Protocole NFS




| Paire de baies de stockage NetApp AFF HA pour le volume de destination  a| 
* AFF A800
* ONTAP 9
* Protocole NFS




| Serveur Fujitsu PRIMERGY RX2540 | Chacun équipé de : * 48 CPU * Intel Xeon * 256 Go de mémoire physique * Port double 10 GbE 


| Réseautage | 10GbE 
|===


== Étapes de déploiement - NAS

Pour déployer NetApp XCP pour le transfert de données, installez et activez d’abord le logiciel XCP sur l’emplacement de destination.  Vous pouvez consulter les détails dans le https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["Guide de l'utilisateur de NetApp XCP"^] .  Pour ce faire, procédez comme suit :

. Répondre aux prérequis détaillés dans la sectionlink:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["Prérequis pour XCP."]
. Téléchargez le logiciel XCP depuis le https://mysupport.netapp.com/site/products/all/details/netapp-xcp/downloads-tab["Page NetApp XCP (Téléchargements)"^] .
. Copiez les fichiers tar XCP téléchargés sur le serveur XCP.
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. Décompressez le fichier tar.
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. Téléchargez la licence à partir de https://xcp.netapp.com/license/xcp.xwic%20["https://xcp.netapp.com/license/xcp.xwic"^] et copier sur le serveur XCP.
. Activer la licence.
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. Recherchez le port NFS source et le serveur NFS de destination.  Le port par défaut est 2049.
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. Vérifiez la connexion NFS.  Vérifiez le serveur NFS (pour la source et la destination) en utilisant telnet sur le port du serveur NFS.
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. Configurer le catalogue.
+
.. Créez un volume NFS et exportez NFS pour le catalogue XCP.  Vous pouvez également exploiter l'exportation NFS du système d'exploitation pour le catalogue XCP.
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. Vérifiez l'exportation NFS.
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. Mise à jour `xcp.ini` .
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. Recherchez les exportations NAS sources en utilisant `xcp show` .  Rechercher:
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. (Facultatif) Scannez les données NAS source.
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
L’analyse des données NAS source vous aide à comprendre la disposition des données et à détecter d’éventuels problèmes de migration.  Le temps de l'opération d'analyse XCP est proportionnel au nombre de fichiers et à la profondeur du répertoire.  Vous pouvez ignorer cette étape si vous connaissez vos données NAS.

. Consultez le rapport créé par `xcp scan` .  Recherchez principalement des dossiers illisibles et des fichiers illisibles.
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. (Facultatif) Modifiez l'inode.  Affichez le nombre d'inodes et modifiez le nombre en fonction du nombre de fichiers à migrer ou à copier pour les volumes de catalogue et de destination (si nécessaire).
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. Scannez le volume de destination.
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. Vérifiez l’espace du volume source et de destination.
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. Copiez les données de la source vers la destination en utilisant `xcp copy` et vérifiez le résumé.
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: Par défaut, XCP crée sept processus parallèles pour copier les données.  Cela peut être réglé.

+

NOTE: NetApp recommande que le volume source soit en lecture seule.  En temps réel, le volume source est un système de fichiers actif et en direct.  Le `xcp copy` l'opération peut échouer car NetApp XCP ne prend pas en charge une source en direct qui est continuellement modifiée par une application.

+
Pour Linux, XCP nécessite un ID d'index car XCP Linux effectue le catalogage.

. (Facultatif) Vérifiez les inodes sur le volume NetApp de destination.
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. Effectuez la mise à jour incrémentielle en utilisant `xcp sync` .
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
Pour ce document, pour simuler en temps réel, le million de fichiers dans les données sources ont été renommés, puis les fichiers mis à jour ont été copiés vers la destination en utilisant `xcp sync` .  Pour Windows, XCP a besoin des chemins source et de destination.

. Valider le transfert de données.  Vous pouvez valider que la source et la destination ont les mêmes données en utilisant `xcp verify` .
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


La documentation XCP fournit plusieurs options (avec des exemples) pour `scan` , `copy` , `sync` , et `verify` opérations.  Pour plus d'informations, consultez le https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["Guide de l'utilisateur de NetApp XCP"^] .


NOTE: Les clients Windows doivent copier les données à l’aide de listes de contrôle d’accès (ACL).  NetApp recommande d'utiliser la commande `xcp copy -acl -fallbackuser\<username> -fallbackgroup\<username or groupname> <source> <destination>` .  Pour des performances maximales, compte tenu du volume source contenant des données SMB avec ACL et des données accessibles par NFS et SMB, la cible doit être un volume NTFS.  À l'aide de XCP (version NFS), copiez les données du serveur Linux et exécutez la synchronisation XCP (version SMB) avec le `-acl` et `-nodata` options du serveur Windows pour copier les ACL des données sources vers les données SMB cibles.

Pour les étapes détaillées, voir https://helpcenter.netwrix.com/NA/Configure_IT_Infrastructure/Accounts/DCA_Manage_Auditing_Security_Log.html["Configuration de la politique « Gérer les journaux d'audit et de sécurité »"^] .



== Étapes de déploiement - Migration des données HDFS/MapRFS

Dans cette section, nous discutons de la nouvelle fonctionnalité XCP appelée Hadoop Filesystem Data Transfer to NAS, qui migre les données de HDFS/MapRFS vers NFS et vice versa.



=== Prérequis

Pour la fonctionnalité MapRFS/HDFS, vous devez effectuer la procédure suivante dans un environnement utilisateur non root.  Normalement, l'utilisateur non root est hdfs, mapr ou un utilisateur autorisé à apporter des modifications au système de fichiers HDFS et MapRFS.

. Définissez les variables CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH et NHDFS_LIBHDFS_PATH dans la CLI ou le fichier .bashrc de l'utilisateur avec le `xcp` commande.
+
** NHDFS_LIBHDFS_PATH pointe vers le fichier libhdfs.so.  Ce fichier fournit des API HDFS pour interagir et manipuler les fichiers et le système de fichiers HDFS/MapRFS dans le cadre de la distribution Hadoop.
** NHDFS_LIBJVM_PATH pointe vers le fichier libjvm.so.  Il s'agit d'une bibliothèque de machine virtuelle JAVA partagée dans l'emplacement jre.
** CLASSPATH pointe vers tous les fichiers jars en utilisant les valeurs (Hadoop classpath –glob).
** LD_LIBRARY_PATH pointe vers l'emplacement du dossier de la bibliothèque native Hadoop.
+
Consultez l’exemple suivant basé sur un cluster Cloudera.

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
Dans cette version, nous prenons en charge les opérations d'analyse, de copie et de vérification XCP ainsi que la migration des données de HDFS vers NFS.  Vous pouvez transférer des données à partir d'un nœud de travail unique et de plusieurs nœuds de travail d'un cluster de lac de données.  Dans la version 1.8, les utilisateurs root et non root peuvent effectuer la migration des données.







=== Étapes de déploiement : un utilisateur non root migre les données HDFS/MaprFS vers NetApp NFS

. Suivez les mêmes étapes mentionnées dans les étapes 1 à 9 de la section Étapes de déploiement.
. Dans l’exemple suivant, l’utilisateur migre des données de HDFS vers NFS.
+
.. Créez un dossier et des fichiers (en utilisant `hadoop fs -copyFromLocal` ) dans HDFS.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. Vérifiez les autorisations dans le dossier HDFS.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. Créez un dossier dans NFS et vérifiez les autorisations.
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. Copiez les fichiers de HDFS vers NFS à l'aide de XCP et vérifiez les autorisations.
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----



